from src.engine_backend.llm_helpers import load_peft_llm, load_tokenizer, llm_generate
from src.engine_constants.engine_constants import PEFT_MODEL_ID, BASE_MODEL_ID, dream_interaction_instructions, dream_scenario_instructions 

def load_engine_llm():
    print('Loading the newborn engine model, please wait...\n')
    engine_tokenizer = load_tokenizer(BASE_MODEL_ID)
    engine_llm = load_peft_llm(PEFT_MODEL_ID, BASE_MODEL_ID)
    print('Model loaded!\n')
    return [engine_llm, engine_tokenizer]

def generate_dream_scenario(engine_llm, engine_tokenizer, prompt, context):
    if(engine_tokenizer == None or engine_llm == None):
        raise Exception('Engine LLM has not been initialized properly.')

    model_input = f"""[INST] <<SYS>> {dream_scenario_instructions}<</SYS>>\n\nBelow is the game context, generate a dream scenario based on it:\n\n{context} [/INST]"""
    
    dream_scenario = llm_generate(engine_llm, engine_tokenizer, model_input)
    output_description = "Below is the dream scenario generated by the engine:"

    print(f"\033[94m{output_description}\033[0m\n")
    print(dream_scenario)

    return f"{output_description}\n\n{dream_scenario}"

def generate_interaction(engine_llm, engine_tokenizer, prompt, context):
    if(engine_tokenizer == None or engine_llm == None):
        raise Exception('Engine LLM has not been initialized properly.')

    model_input = f"""[INST] <<SYS>> {dream_interaction_instructions}<</SYS>>\n\nBelow is the game context up until this point, please generate further dream context and interactions in response:\n\n{context} [/INST]"""

    interaction = llm_generate(engine_llm, engine_tokenizer, model_input)
    output_description = "Below is the next interaction generated by the engine:"

    print(f"\033[94m{output_description}\033[0m\n")
    print(interaction)
    
    return f"{output_description}\n\n{interaction}"